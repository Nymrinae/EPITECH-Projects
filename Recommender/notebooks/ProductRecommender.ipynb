{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProductRecommender.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z3YtB3WBcA4",
        "outputId": "0b75eef2-da0a-41f1-fd37-cc7d4fb96770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_recommenders in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_recommenders) (1.0.0)\n",
            "Requirement already satisfied: tensorflow>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_recommenders) (2.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.1.6->tensorflow_recommenders) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (0.23.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.43.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (12.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (3.10.0.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (0.37.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.6.0->tensorflow_recommenders) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.6.0->tensorflow_recommenders) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow_recommenders) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_recommenders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from google.colab import drive\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "xT3YD9_BCc1d"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data setup"
      ],
      "metadata": {
        "id": "xZW8ZX3hCp2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/Machine Learning/recommender/KaDo.h5' -d '/content/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuTxmt0UCozT",
        "outputId": "edb2f36d-26b3-47f3-cd9c-37b8877cb2bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_HDF5_PATH = '/content/KaDo.h5'"
      ],
      "metadata": {
        "id": "9grzcx5-FW6N"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_hdf(DATASET_HDF5_PATH)"
      ],
      "metadata": {
        "id": "z42UKR8EHtyN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "h6zt5QibHwDs",
        "outputId": "0219bae0-9e3e-4af0-ba12-e1e8ec03f480"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c3de179a-52d9-4617-864d-4674f5f599d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TICKET_ID</th>\n",
              "      <th>MOIS_VENTE</th>\n",
              "      <th>PRIX_NET</th>\n",
              "      <th>FAMILLE</th>\n",
              "      <th>UNIVERS</th>\n",
              "      <th>MAILLE</th>\n",
              "      <th>LIBELLE</th>\n",
              "      <th>CLI_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>35592159</td>\n",
              "      <td>10</td>\n",
              "      <td>1.67</td>\n",
              "      <td>HYGIENE</td>\n",
              "      <td>HYG_DOUCHE JARDINMONDE</td>\n",
              "      <td>HYG_JDM</td>\n",
              "      <td>GD JDM4 PAMPLEMOUSSE FL 200ML</td>\n",
              "      <td>1490281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35592159</td>\n",
              "      <td>10</td>\n",
              "      <td>1.66</td>\n",
              "      <td>HYGIENE</td>\n",
              "      <td>HYG_DOUCHE JARDINMONDE</td>\n",
              "      <td>HYG_JDM</td>\n",
              "      <td>GD JDM4 PAMPLEMOUSSE FL 200ML</td>\n",
              "      <td>1490281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35592159</td>\n",
              "      <td>10</td>\n",
              "      <td>7.45</td>\n",
              "      <td>SOINS DU VISAGE</td>\n",
              "      <td>VIS_CJOUR Jeunes Specifique</td>\n",
              "      <td>VIS_JEUNE_ET_LEVRE</td>\n",
              "      <td>CR JR PARF BIO.SPE AC.SENT.50ML</td>\n",
              "      <td>1490281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35592159</td>\n",
              "      <td>10</td>\n",
              "      <td>5.95</td>\n",
              "      <td>SOINS DU VISAGE</td>\n",
              "      <td>VIS_DEMAQ AAAR</td>\n",
              "      <td>VIS_AAAR_DEMAQLOTION</td>\n",
              "      <td>EAU MICELLAIRE 3 THES FL200ML</td>\n",
              "      <td>1490281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35592159</td>\n",
              "      <td>10</td>\n",
              "      <td>1.67</td>\n",
              "      <td>HYGIENE</td>\n",
              "      <td>HYG_DOUCHE JARDINMONDE</td>\n",
              "      <td>HYG_JDM</td>\n",
              "      <td>GD JDM4 TIARE FL 200ML</td>\n",
              "      <td>1490281</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3de179a-52d9-4617-864d-4674f5f599d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3de179a-52d9-4617-864d-4674f5f599d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3de179a-52d9-4617-864d-4674f5f599d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   TICKET_ID  MOIS_VENTE  ...                          LIBELLE   CLI_ID\n",
              "0   35592159          10  ...    GD JDM4 PAMPLEMOUSSE FL 200ML  1490281\n",
              "1   35592159          10  ...    GD JDM4 PAMPLEMOUSSE FL 200ML  1490281\n",
              "2   35592159          10  ...  CR JR PARF BIO.SPE AC.SENT.50ML  1490281\n",
              "3   35592159          10  ...    EAU MICELLAIRE 3 THES FL200ML  1490281\n",
              "4   35592159          10  ...           GD JDM4 TIARE FL 200ML  1490281\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mORbRsBvI8Se",
        "outputId": "01f833e1-d0e1-4d10-e07f-87cfd9c837ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TICKET_ID       uint32\n",
              "MOIS_VENTE       uint8\n",
              "PRIX_NET       float32\n",
              "FAMILLE       category\n",
              "UNIVERS       category\n",
              "MAILLE        category\n",
              "LIBELLE       category\n",
              "CLI_ID          uint32\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[['FAMILLE', 'UNIVERS', 'MAILLE', 'LIBELLE']].drop_duplicates().count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kROOBi12QWTp",
        "outputId": "8b4fe61c-0aa7-4a1b-e4d0-941256118046"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FAMILLE    1484\n",
              "UNIVERS    1484\n",
              "MAILLE     1484\n",
              "LIBELLE    1484\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['FAMILLE'] = df['FAMILLE'].astype(str)\n",
        "df['UNIVERS'] = df['UNIVERS'].astype(str)\n",
        "df['MAILLE'] = df['MAILLE'].astype(str)\n",
        "df['LIBELLE'] = df['LIBELLE'].astype(str)"
      ],
      "metadata": {
        "id": "nk9PIoM3ZCNX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_id_lookup = tf.keras.layers.IntegerLookup()\n",
        "client_id_lookup.adapt(df['CLI_ID'].unique())\n",
        "\n",
        "month_lookup = tf.keras.layers.IntegerLookup()\n",
        "month_lookup.adapt(df['MOIS_VENTE'].unique())"
      ],
      "metadata": {
        "id": "d4twobtfd4QL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_family_lookup = tf.keras.layers.StringLookup()\n",
        "product_family_lookup.adapt(df['FAMILLE'].unique())\n",
        "\n",
        "product_universe_lookup = tf.keras.layers.StringLookup()\n",
        "product_universe_lookup.adapt(df['UNIVERS'].unique())\n",
        "\n",
        "product_mesh_lookup = tf.keras.layers.StringLookup()\n",
        "product_mesh_lookup.adapt(df['MAILLE'].unique())\n",
        "\n",
        "product_label_lookup = tf.keras.layers.StringLookup()\n",
        "product_label_lookup.adapt(df['LIBELLE'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zX6lfciiPKdR",
        "outputId": "51a7c76b-fd0f-4756-d03d-2f2d35557dad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 26680 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f0a2f938cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 26682 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7f0a2f07c830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Vocabulary: {product_label_lookup.get_vocabulary()[:4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql8UHCd4T9IY",
        "outputId": "17027f5f-c71f-4c19-e9ac-b7c47b3543f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['[UNK]', 'x99SS GELEE FRUITS VANIL PN2 10ML', 'ZERO TRACE SPRAY SPF 30 150ML', 'ZERO TRACE SPRAY SPF 15 FL150']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClientModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.client_embedding = tf.keras.Sequential([\n",
        "            client_id_lookup,\n",
        "            tf.keras.layers.Embedding(client_id_lookup.vocabulary_size(), 64),\n",
        "        ])\n",
        "\n",
        "        self.month_embedding = tf.keras.Sequential([\n",
        "            month_lookup,\n",
        "            tf.keras.layers.Embedding(month_lookup.vocabulary_size(), 64)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "\n",
        "        # Take the input dictionary, pass it through each input layer,\n",
        "        # and concatenate the result.\n",
        "        return tf.concat([\n",
        "            self.client_embedding(inputs[\"CLI_ID\"]),\n",
        "            self.month_embedding(inputs[\"MOIS_VENTE\"])\n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "xzRDNpWScPJ0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        max_tokens = 10_000\n",
        "\n",
        "        self.label_embedding = tf.keras.Sequential([\n",
        "            product_label_lookup,\n",
        "            tf.keras.layers.Embedding(product_label_lookup.vocabulary_size(), 32)\n",
        "        ])\n",
        "\n",
        "        self.family_embedding = tf.keras.Sequential([\n",
        "            product_family_lookup,\n",
        "            tf.keras.layers.Embedding(product_family_lookup.vocabulary_size(), 32)\n",
        "        ])\n",
        "\n",
        "        self.universe_embedding = tf.keras.Sequential([\n",
        "            product_universe_lookup,\n",
        "            tf.keras.layers.Embedding(product_universe_lookup.vocabulary_size(), 32)\n",
        "        ])\n",
        "\n",
        "        self.mesh_embedding = tf.keras.Sequential([\n",
        "            product_mesh_lookup,\n",
        "            tf.keras.layers.Embedding(product_mesh_lookup.vocabulary_size(), 32)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.concat([\n",
        "            self.label_embedding(inputs['LIBELLE']),\n",
        "            self.family_embedding(inputs['FAMILLE']),\n",
        "            self.universe_embedding(inputs['UNIVERS']),\n",
        "            self.mesh_embedding(inputs['MAILLE']),\n",
        "        ], axis=1)"
      ],
      "metadata": {
        "id": "DyH3ECetX0cQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "product_df = df[['FAMILLE', 'UNIVERS', 'MAILLE', 'LIBELLE']].drop_duplicates()\n",
        "product_ds = tf.data.Dataset.from_tensor_slices(dict(product_df))\n",
        "\n",
        "purchase_history_df = tf.data.Dataset.from_tensor_slices(dict(df))"
      ],
      "metadata": {
        "id": "kdAR663foocn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProductRecommenderModel(tfrs.Model):\n",
        "\n",
        "  def __init__(self, client_model, product_model):\n",
        "    super().__init__()\n",
        "    self.client_model: tf.keras.Model = client_model\n",
        "    self.product_model: tf.keras.Model = product_model\n",
        "    self.task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
        "        metrics=tfrs.metrics.FactorizedTopK(\n",
        "            candidates=product_ds.batch(128).map(self.product_model)\n",
        "        )\n",
        "    )\n",
        "\n",
        "  def compute_loss(self, features, training=False) -> tf.Tensor:\n",
        "    # We pick out the user features and pass them into the user model.\n",
        "    client_embeddings = self.client_model(features)\n",
        "    # And pick out the movie features and pass them into the movie model,\n",
        "    # getting embeddings back.\n",
        "    product_embeddings = self.product_model(features)\n",
        "\n",
        "    # The task computes the loss and the metrics.\n",
        "    return self.task(client_embeddings, product_embeddings)"
      ],
      "metadata": {
        "id": "pb2UqTQegBNV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "shuffled = purchase_history_df.shuffle(8_000_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(6_000_000)\n",
        "test = shuffled.skip(6_000_000).take(2_000_000)"
      ],
      "metadata": {
        "id": "MTOHqRvWqnsl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client_model = ClientModel()\n",
        "product_model = ProductModel()\n",
        "model = ProductRecommenderModel(client_model, product_model)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
      ],
      "metadata": {
        "id": "R-qbvkE6tPIi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cached_train = train.shuffle(6_000_000).batch(512).cache()\n",
        "cached_test = test.batch(4096).cache()"
      ],
      "metadata": {
        "id": "Ot2K2fpFzNMA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(cached_train, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg1HQVk4zWYC",
        "outputId": "7b1e2669-5114-4158-c28d-b4028af78cd0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "11719/11719 [==============================] - 2195s 182ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0068 - factorized_top_k/top_5_categorical_accuracy: 0.1035 - factorized_top_k/top_10_categorical_accuracy: 0.1580 - factorized_top_k/top_50_categorical_accuracy: 0.3156 - factorized_top_k/top_100_categorical_accuracy: 0.4032 - loss: 2892.2973 - regularization_loss: 0.0000e+00 - total_loss: 2892.2973\n",
            "Epoch 2/3\n",
            "11719/11719 [==============================] - 1953s 167ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0302 - factorized_top_k/top_5_categorical_accuracy: 0.2702 - factorized_top_k/top_10_categorical_accuracy: 0.3812 - factorized_top_k/top_50_categorical_accuracy: 0.6274 - factorized_top_k/top_100_categorical_accuracy: 0.7252 - loss: 2315.2513 - regularization_loss: 0.0000e+00 - total_loss: 2315.2513\n",
            "Epoch 3/3\n",
            "11719/11719 [==============================] - 1929s 165ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0410 - factorized_top_k/top_5_categorical_accuracy: 0.3331 - factorized_top_k/top_10_categorical_accuracy: 0.4604 - factorized_top_k/top_50_categorical_accuracy: 0.7149 - factorized_top_k/top_100_categorical_accuracy: 0.8034 - loss: 2028.1424 - regularization_loss: 0.0000e+00 - total_loss: 2028.1424\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a2f0baed0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(cached_test, return_dict=True)"
      ],
      "metadata": {
        "id": "-aOT-WWmRao3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}